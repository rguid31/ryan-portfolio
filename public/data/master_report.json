{
  "metadata": {
    "version": "2.0",
    "lastUpdated": "2026-02-09",
    "completeness": 0.75,
    "purpose": "Single source of truth for professional website, resumes, and AI agents",
    "schemaVersion": "1.0"
  },
  "personal": {
    "fullName": "Ryan Michael Guidry",
    "firstName": "Ryan",
    "lastName": "Guidry",
    "location": {
      "city": "Baton Rouge",
      "state": "Louisiana",
      "country": "United States",
      "timezone": "America/Chicago"
    },
    "contact": {
      "email": "inquireryan@gmail.com",
      "phone": "(985) 722-7475",
      "website": "http://www.ryanguidry.com"
    },
    "social": {
      "linkedin": "http://linkedin.com/in/rmguidry",
      "github": "http://github.com/rguid31",
      "twitter": "http://x.com/inquireryan"
    },
    "availability": {
      "status": "open",
      "preferredRoles": [
        "Technical Writer",
        "Data Scientist",
        "AI/ML Engineer",
        "Web/App Developer"
      ],
      "workPreferences": [
        "Remote",
        "Hybrid",
        "On-site (Baton Rouge area)"
      ],
      "startDate": "Immediate (2-week notice if currently employed)"
    }
  },
  "summary": {
    "headline": "Math & AI Specialist | Turning Ideas into Reality with Data & Logic",
    "tagline": "Building an AI that turns ideas into reality using my experiences as a Chemical Engineering Academic, Data Analysis Professional, Future Mathematics Major, & AI Advocate",
    "description": "Mathematically minded problem solver with a passion for turning complex data into actionable insights. Currently pursuing a B.S. in Mathematics with a secondary discipline in Chemical Engineering at LSU (88/120 credits complete), building a strong foundation in statistical analysis, computational modeling, and applied problem-solving. My career shift from chemical engineering to mathematics reflects my commitment to data-driven decision-making and my interest in the rapidly evolving fields of analytics, machine learning, and AI.",
    "coreCompetencies": [
      "Data Analysis & Visualization (Python, SQL, Tableau)",
      "Statistical Modeling (Regression, Hypothesis Testing)",
      "Process Optimization & Efficiency Modeling",
      "AI/ML Model Training & Evaluation (RLHF)",
      "Technical Innovation & Field Instrumentation"
    ],
    "valueProposition": "Merging mathematical rigor, data science skills, and creative problem-solving to deliver measurable impact in innovation-driven environments."
  },
  "projects": [
    {
      "id": "down-the-bayou-meats",
      "projectName": "Down the Bayou Meats",
      "slug": "down-the-bayou-meats",
      "category": "Full-Stack Infrastructure & Brand Architecture",
      "status": "Active / In-Development",
      "featured": true,
      "order": 1,
      "projectDescription": "Born from the need to modernize a traditional Cajun specialty meat business, this project transitions a brick-and-mortar legacy into the digital age. It captures the 'Down the Bayou' heritage while meeting modern e-commerce standards.",
      "shortDescription": "Modernizing a Cajun specialty meat business with a scalable e-commerce platform.",
      "myRole": "Lead Systems Developer & Brand Architect",
      "responsibilities": [
        "End-to-end site deployment: Managed domain registration, DNS configuration, and secure hosting environment.",
        "Infrastructure Setup: Configured SSL certificates and SMTP protocols for professional domain-based email and reliable contact form delivery.",
        "Semantic SEO & AI Optimization: Implemented machine-readable metadata and descriptive alt-text strategies to optimize for LLM crawlers and AI search agents.",
        "Marketing Operations: Architected mailing list audience segments and lead generation workflows via integrated Contact Form 7.",
        "Accessibility & UX Design: Engineered a WCAG-compliant high-contrast color scheme (Barn Red/Gold/Cream) and responsive Flexbox grid system.",
        "Dynamic Inventory Sync: Real-time updates between the online store and physical stock levels.",
        "Custom Shipping Logic: Implemented specialized shipping zones and rates for perishable goods (cold chain logistics).",
        "Automated Email Pipelines: Post-purchase customer journeys built to encourage repeat orders."
      ],
      "techStack": [
        "WordPress",
        "Elementor Pro",
        "WooCommerce",
        "Google Workspace",
        "SSL/TLS",
        "SMTP",
        "Yoast SEO"
      ],
      "techCategories": {
        "platform": [
          "WordPress",
          "Elementor Pro",
          "WooCommerce"
        ],
        "infrastructure": [
          "Custom Shipping API",
          "DNS Management",
          "SSL/TLS",
          "SMTP Protocols"
        ],
        "business": [
          "Google Workspace",
          "Yoast SEO"
        ]
      },
      "challengesFaced": [
        {
          "challenge": "Complex Perishable Shipping",
          "description": "Managing complex shipping calculations for weight-based perishable items was inconsistent, leading to potential logistics losses.",
          "solution": "Integrated a custom shipping API that calculated real-time rates based on zip-code distance and packaging weight.",
          "result": "Ensured accurate logistics pricing and expanded reach to statewide shipping."
        }
      ],
      "keyLearnings": [
        "Mastered advanced DNS and SMTP configuration for business-critical communications",
        "Developed strategies for AI-first SEO and machine-readable web content",
        "Applied WCAG standards to branding and UI design",
        "Streamlined lead generation through integrated marketing workflows"
      ],
      "impactMetrics": {
        "reach": "Expanded from local-only to statewide shipping",
        "efficiency": "25% increase in operational efficiency through automation",
        "uptime": "99.9%",
        "accessibility": "WCAG Compliant"
      },
      "developmentTimeline": {
        "duration": "Ongoing",
        "phases": [
          "DNS & Infrastructure",
          "UX Design & Branding",
          "SEO & AI Optimization"
        ]
      },
      "roadmap": [
        "Integration of a subscription-based 'Boudin of the Month' club",
        "Loyalty rewards program implementation"
      ],
      "targetAudience": "Customers, LLM Crawlers, and AI Search Agents",
      "projectURL": "https://downthebayoumeats.com",
      "narrative": "Modernizing a brick-and-mortar legacy business requires more than a storefront; it requires a digital transformation of brand heritage. The purpose of this project is to build a scalable e-commerce infrastructure that preserves 'Down the Bayou' identity while optimizing for national logistics and AI discoverability.",
      "conceptualArchitecture": "The platform is built on a decoupled architecture where the content management (WordPress) is hardened with specialized business logic for perishable logistics. It follows a 'Data-First' pattern, ensuring that every product attribute is machine-readable for both human customers and AI search agents.",
      "repoURL": "",
      "images": [
        "/assets/dtb-hero.png",
        "/assets/dtb-checkout.gif"
      ]
    },
    {
      "id": "synaptic-insight-engine",
      "projectName": "Synaptic Insight Engine",
      "slug": "synaptic-insight-engine",
      "category": "AI/ML - Full-Stack Application",
      "status": "Active",
      "featured": true,
      "order": 2,
      "projectDescription": "An AI-powered platform that represents the intersection of large language models and user-centric design. Designed as a 'second brain' interface for high-context, conversational AI interactions using Google Gemini.",
      "shortDescription": "AI-powered conversation platform using Google Gemini API",
      "myRole": "Sole Developer - Architected and implemented entire solution end-to-end",
      "responsibilities": [
        "System architecture and database design",
        "Frontend development (responsive UI/UX)",
        "Backend API development and AI integration",
        "Deployment and production optimization",
        "Ongoing maintenance and feature development",
        "Streaming Responses: Implemented Server-Sent Events (SSE) to display AI text progressively.",
        "Context Memory: Session-based history management system for conversational continuity.",
        "Markdown Rendering: Full support for code snippets and formatted text."
      ],
      "techStack": [
        "JavaScript ES6+",
        "Node.js",
        "Express.js",
        "Google Gemini API (Vertex AI)",
        "Supabase",
        "PostgreSQL",
        "HTML5",
        "CSS Grid/Flexbox",
        "Vercel"
      ],
      "techCategories": {
        "frontend": [
          "JavaScript ES6+",
          "HTML5",
          "CSS Grid/Flexbox"
        ],
        "backend": [
          "Node.js",
          "Express.js"
        ],
        "ai": [
          "Google Gemini API (Vertex AI)",
          "SSE Streaming"
        ],
        "database": [
          "Supabase",
          "PostgreSQL"
        ],
        "deployment": [
          "Vercel"
        ]
      },
      "challengesFaced": [
        {
          "challenge": "API Latency & UI Blocking",
          "description": "Managing API rate limits and long response times led to UI 'freezing' for heavy requests.",
          "solution": "Implemented an asynchronous queue and a loading state manager with SSE streaming.",
          "result": "Responsive UI maintained with < 200ms initial server response time."
        }
      ],
      "keyLearnings": [
        "Mastered integration of generative AI APIs into production applications",
        "Developed expertise in serverless architecture patterns (Vercel + Supabase)",
        "Advanced skills in real-time data synchronization and state management",
        "Deepened understanding of prompt engineering for optimal AI responses"
      ],
      "impactMetrics": {
        "responseTime": "< 200ms initial response",
        "uptime": "99.5%",
        "capabilities": "Integrated multi-modal prompting",
        "bugs": "0 critical bugs in production"
      },
      "developmentTimeline": {
        "duration": "3 months",
        "phases": [
          "Concept",
          "Development",
          "Deployment"
        ]
      },
      "roadmap": [
        "Adding image input support",
        "Local vector storage for personalized user knowledge bases"
      ],
      "targetAudience": "Researchers, entrepreneurs, students, and professionals seeking AI-powered insights",
      "projectURL": "https://synaptic-insight-engine.vercel.app",
      "narrative": "As AI moves from novelty to utility, the need for 'Second Brain' interfaces grows. This project explores the intersection of high-context LLMs and intuitive user design, providing a high-performance playground for conversational intelligence using the Google Gemini API.",
      "conceptualArchitecture": "Architected as a real-time reactive system, the engine utilizes Server-Sent Events (SSE) for streaming AI responses and a session-based state manager. This 'Persistent Context' pattern ensures conversational continuity across complex multi-turn interactions.",
      "repoURL": "https://github.com/rguid31/synaptic-insight-engine",
      "images": [
        "/assets/synaptic-ui.png",
        "/assets/api-response.gif"
      ]
    },
    {
      "id": "ryan-portfolio",
      "projectName": "Ryan Guidry — Digital Twin Portfolio",
      "slug": "ryan-portfolio",
      "category": "Full-Stack Architecture — Data-Driven Web Platform",
      "status": "Active — Ongoing Development",
      "featured": true,
      "order": 0,
      "projectDescription": "A self-documenting, data-driven professional platform built on Next.js 16 and React 19. The site uses a single JSON 'Digital Twin' as the source for all profile data, identity, and projects.",
      "shortDescription": "Self-documenting Next.js 16 platform powered by a 'digital twin' JSON architecture.",
      "myRole": "Sole Architect, Developer & Designer — end-to-end ownership from data modeling to DNS configuration",
      "responsibilities": [
        "Designed the 'digital twin' JSON schema — a 12-section, deeply nested data model covering all professional facets.",
        "Built a fully typed data access layer (masterReport.ts) with 11 accessor functions.",
        "Architected Next.js App Router routes with React Server Components for zero-JS page loads.",
        "Implemented dynamic project routing with generateStaticParams.",
        "Lighthouse Optimization: Achieved 100/100 performance scores across all pages.",
        "React Compiler Integration: Leveraged automatic memoization for optimized rendering."
      ],
      "techStack": [
        "Next.js 16.1.6",
        "React 19.2.3",
        "React Compiler",
        "TypeScript 5+",
        "Tailwind CSS 4",
        "CSS3",
        "ESLint 9",
        "PostCSS",
        "Node.js",
        "Vercel",
        "Git/GitHub"
      ],
      "techCategories": {
        "framework": [
          "Next.js 16.1.6",
          "React 19.2.3 (RSC, Server Actions)"
        ],
        "performance": [
          "React Compiler (Babel-plugin-react-compiler)",
          "Static Site Generation (SSG)"
        ],
        "language": [
          "TypeScript 5+ (Strict Mode)"
        ],
        "styling": [
          "Tailwind CSS 4",
          "Atomic Design Patterns"
        ],
        "dataArchitecture": [
          "JSON-as-CMS (Digital Twin Pattern)",
          "Typed data access layer (masterReport.ts)"
        ],
        "deployment": [
          "Vercel (CI/CD, Edge Network, Custom DNS)"
        ]
      },
      "challengesFaced": [
        {
          "challenge": "Balancing High-Perf Features with Stability",
          "description": "Balancing high-performance React 19 and Next.js 16 features with stable production deployment.",
          "solution": "Leveraged the new React Compiler to eliminate manual useMemo calls, reducing bundle size by 15%.",
          "result": "Zero-config updates and 100/100 Lighthouse performance score."
        }
      ],
      "keyLearnings": [
        "Mastered Next.js 16 App Router with React Server Components",
        "Built a production TypeScript data access layer with 13 interfaces",
        "Developed expertise in static site generation with dynamic data",
        "Learned end-to-end DNS configuration and CDN distribution"
      ],
      "impactMetrics": {
        "performance": "100/100 Google Lighthouse score",
        "bundleSize": "15% reduction via React Compiler",
        "typeSafety": "100% TypeScript coverage",
        "deployment": "CI/CD < 60 second build time"
      },
      "developmentTimeline": {
        "duration": "Ongoing",
        "phases": [
          "Data Architecture & JSON Schema",
          "Core Platform Build",
          "Vercel & DNS Deployment",
          "Continuous Content Iteration"
        ]
      },
      "roadmap": [
        "Adding a real-time 'Current Study' widget pulling from LSU course schedules API"
      ],
      "targetAudience": "Recruiters, hiring managers, and technical audiences evaluating full-stack architecture skills",
      "projectURL": "https://ryanguidry.com",
      "narrative": "A professional portfolio should be more than a static document; it should be a data-driven mirror of professional identity. This 'Digital Twin' platform uses a single JSON source of truth to power a high-performance, self-documenting ecosystem built on the bleeding edge of Next.js and React.",
      "conceptualArchitecture": "The architecture follows a 'Single Source of Truth' (SSOT) pattern, where a central JSON schema drives every route, component, and metadata tag. By leveraging React Server Components (RSC) and the React Compiler, the system achieves near-zero client-side JS while maintaining dynamic data fidelity.",
      "repoURL": "https://github.com/rguid31/ryan-portfolio",
      "images": [
        "/assets/portfolio-lighthouse.png",
        "/assets/json-architecture.png"
      ]
    },
    {
      "id": "ai-image-tagging-tool",
      "projectName": "AI-Powered Image Tagging Tool",
      "slug": "ai-image-tagging-tool",
      "category": "AI/ML - Computer Vision & Automation",
      "status": "Active",
      "featured": true,
      "order": 3,
      "projectDescription": "A Python-based CLI tool that leverages OpenAI's CLIP model and GPT-4 to automatically categorize thousands of images instantly. It 'sees' the image and writes accurate, SEO-friendly tags.",
      "shortDescription": "Python CLI tool using CLIP and GPT-4 for automated image tagging.",
      "myRole": "Sole Developer - Complete development from research to deployment",
      "responsibilities": [
        "AI model research and selection (evaluated CLIP, BLIP, ViT).",
        "Python architecture and CLI design using the 'argparse' pattern.",
        "Image Processing: Multi-threaded batch handling for performance at scale.",
        "Zero-Shot Classification: Categorizing images without pre-trained label sets.",
        "JSON Export Integration: Metadata output ready for database ingestion."
      ],
      "techStack": [
        "Python 3.9+",
        "OpenAI CLIP",
        "GPT-4",
        "Pillow",
        "OpenCV",
        "Click",
        "argparse"
      ],
      "techCategories": {
        "core": [
          "Python 3.9+"
        ],
        "mlModels": [
          "OpenAI CLIP (Vision Embedding)",
          "GPT-4 (Natural Language Refinement)"
        ],
        "imageHandling": [
          "Pillow",
          "OpenCV"
        ],
        "interface": [
          "argparse",
          "Click CLI Patterns"
        ]
      },
      "challengesFaced": [
        {
          "challenge": "Contextual Tag Refinement",
          "description": "CLIP occasionally provided tags that were too 'literal' and lacked human-readable context.",
          "solution": "Added a GPT-4 'Refiner' step that transforms CLIP’s raw data into descriptive tags.",
          "result": "Reduced tagging time from 2 minutes to under 3 seconds per image with high accuracy."
        }
      ],
      "keyLearnings": [
        "Gained hands-on experience with state-of-the-art vision models (CLIP)",
        "Mastered OpenAI API integration and prompt engineering for vision tasks",
        "Developed expertise in Python CLI tool design and UX",
        "Learned image processing pipelines and batch optimization"
      ],
      "impactMetrics": {
        "processingTime": "< 3 seconds per image",
        "efficiency": "97.5% reduction in manual tagging time",
        "accuracy": "85%+ tag relevance",
        "batchScale": "Parallel processing of hundreds of files"
      },
      "developmentTimeline": {
        "duration": "3 months",
        "phases": [
          "Model Research & Prototyping",
          "CLI Implementation & Batch Flow",
          "GPT Refiner Integration",
          "Testing & Documentation"
        ]
      },
      "roadmap": [
        "Development of a GUI version using PyQt or Tkinter"
      ],
      "targetAudience": "Photographers, digital asset managers, and content creators",
      "projectURL": null,
      "narrative": "As visual data grows, manual organization becomes impossible. This CLI tool was built for photographers and developers who need to categorize thousands of images instantly. By combining OpenAI’s CLIP and GPT-4, the tool 'sees' the image and 'writes' accurate, SEO-friendly tags.",
      "conceptualArchitecture": "The tool implements a 'Vision-to-Language' pipeline. It uses OpenAI CLIP for zero-shot image embedding and GPT-4 for semantic refinement. This modular architecture allows for parallel processing of image batches, significantly reducing latency for large-scale migrations.",
      "repoURL": "https://github.com/rguid31/image-tagging-tool",
      "images": [
        "/assets/cli-demo.gif",
        "/assets/tag-cloud.png"
      ]
    },
    {
      "id": "music-library-cleaner",
      "projectName": "Music Library Cleaner",
      "slug": "music-library-cleaner",
      "category": "Automation - Data Processing",
      "status": "Active",
      "featured": false,
      "order": 4,
      "projectDescription": "A Python automation tool built to clean, organize, and standardize metadata for massive music libraries. It reflects a passion for clean data and organized systems through recursive file-tree traversal and API integration.",
      "shortDescription": "Python CLI tool for automated music library organization and metadata cleanup.",
      "narrative": "For audiophiles with massive local libraries, inconsistent metadata is a nightmare. This tool was built to automate the tedious process of cleaning ID3 tags and organizing file structures. It reflects a passion for clean data and organized systems.",
      "conceptualArchitecture": "The tool uses a recursive traversal engine to map massive file systems. It leverages 'Acoustic Fingerprinting' (AcoustID) to identify tracks by sound profiles, ensuring accuracy even when initial metadata is absent. This 'Identity-First' pattern prevents data corruption across high-volume libraries.",
      "myRole": "Sole Developer - End-to-end ownership",
      "responsibilities": [
        "Requirements analysis and Python architecture design.",
        "Acoustic Fingerprinting: Identifying songs by their sound wave rather than just the filename.",
        "Regex-based Renaming: Standardizing naming conventions (e.g., 'Artist - Title.mp3').",
        "Album Art Extraction: Automatically finding and embedding high-res covers.",
        "MusicBrainz API Integration: Fetching accurate metadata for inconsistent tags.",
        "Robust Error Handling: Implemented a 'Quarantine' flow for corrupted audio files."
      ],
      "techStack": [
        "Python 3.9+",
        "Mutagen",
        "PyDub",
        "MusicBrainz API",
        "AcoustID",
        "argparse",
        "pandas"
      ],
      "techCategories": {
        "core": [
          "Python 3.9+"
        ],
        "audio": [
          "Mutagen (Tagging)",
          "PyDub (Manipulation)",
          "AcoustID (Fingerprinting)"
        ],
        "apis": [
          "MusicBrainz API"
        ],
        "cli": [
          "argparse"
        ]
      },
      "challengesFaced": [
        {
          "challenge": "Handling Corrupted Audio Files",
          "description": "Corrupted audio files would frequently crash the script during processing.",
          "solution": "Implemented a robust try-except block and a 'Quarantine' folder system.",
          "result": "Processed a library of 5,000+ tracks in under 10 minutes without interruption."
        }
      ],
      "keyLearnings": [
        "Mastered Python audio processing libraries and metadata standards",
        "Developed expertise in file system operations and batch processing",
        "Learned API integration patterns for music metadata services",
        "Understood audio fingerprinting algorithms and duplicate detection"
      ],
      "impactMetrics": {
        "scale": "5,000+ tracks processed",
        "speed": "10 minutes for full library cleanup",
        "accuracy": "90%+ metadata improvement",
        "reliability": "100% crash-resistance via quarantine flow"
      },
      "developmentTimeline": {
        "duration": "2 months",
        "phases": [
          "Research & Proof-of-Concept",
          "Core Tagging Engine Build",
          "API Integration & Fingerprinting",
          "CLI Refinement & Testing"
        ]
      },
      "roadmap": [
        "Full integration with the MusicBrainz API for 100% accurate metadata fetching"
      ],
      "targetAudience": "Music enthusiasts, DJs, and audio engineers",
      "projectURL": null,
      "repoURL": "https://github.com/rguid31/music-library-cleaner",
      "images": [
        "/assets/music-before-after.png"
      ]
    },
    {
      "id": "cosmic-audio-visualizer",
      "projectName": "Cosmic Audio Visualizer",
      "slug": "cosmic-audio-visualizer",
      "category": "Web Development - Creative Coding",
      "status": "Active",
      "featured": true,
      "order": 5,
      "projectDescription": "An experimental web project that turns sound frequencies into a particle-based 'cosmos.' Designed for creators and music enthusiasts who want an immersive, real-time visual experience in their browser.",
      "shortDescription": "Real-time browser audio visualizer with cosmic particle effects.",
      "narrative": "Music isn't just for hearing; it’s for seeing. The Cosmic Audio Visualizer uses the Web Audio API to analyze sound frequencies in real-time and render them as dynamic particle systems and nebula effects.",
      "conceptualArchitecture": "Built on the Web Audio API, the visualizer uses a 'Fast Fourier Transform' (FFT) analysis pipeline. The frequency data is mapped to particle attributes (size, speed, color) via a high-performance rendering loop optimized for 60fps browser interactions.",
      "myRole": "Sole Developer - Creative coding and audio engineering",
      "responsibilities": [
        "Web Audio API: High-performance real-time frequency analysis.",
        "Frequency Binning: Mapping low-end to particle size and high-end to movement speed.",
        "Real-time Mic Input: Visualize live environmental audio.",
        "Custom Color Shaders: Mathematical gradients that shift with the mood of the music.",
        "Performance Optimization: requestAnimationFrame loop for 60 FPS rendering."
      ],
      "techStack": [
        "JavaScript ES6+",
        "HTML5 Canvas",
        "Web Audio API",
        "CSS3",
        "Vercel"
      ],
      "techCategories": {
        "rendering": [
          "HTML5 Canvas (2D/3D Context)",
          "RequestAnimationFrame"
        ],
        "audio": [
          "Web Audio API (Frequency Analysis)"
        ],
        "platform": [
          "Vercel"
        ]
      },
      "challengesFaced": [
        {
          "challenge": "Canvas Rendering Lag",
          "description": "Encountered significant lag when rendering thousands of particles simultaneously on the main context.",
          "solution": "Optimized the particle loop by using 'off-screen' canvases and reducing frequency of unnecessary DOM updates.",
          "result": "Maintains 60 FPS even with 2,000+ active particles."
        }
      ],
      "keyLearnings": [
        "Mastered Web Audio API and real-time frequency analysis",
        "Developed expertise in HTML5 Canvas animation and particle systems",
        "Learned performance optimization for real-time graphics rendering",
        "Gained experience in creative coding and generative art"
      ],
      "impactMetrics": {
        "performance": "60 FPS steady",
        "scale": "2,000+ active particles rendered simultaneously",
        "latency": "Real-time audio-to-visual mapping"
      },
      "developmentTimeline": {
        "duration": "2 weeks",
        "phases": [
          "Audio Analysis Engine",
          "Particle System Development",
          "Shader & Color Logic",
          "Performance Optimization"
        ]
      },
      "roadmap": [
        "Transitioning to Three.js for a full 3D 'Galactic' visualizer mode"
      ],
      "targetAudience": "Music enthusiasts, creative coders, and visual artists",
      "projectURL": "https://cosmic-audio-visualizer.vercel.app",
      "repoURL": "https://github.com/rguid31/cosmic-audio-visualizer",
      "images": [
        "/assets/visualizer-demo.gif"
      ]
    },
    {
      "id": "cajun-specialty-meats",
      "projectName": "Down the Bayou Cajun Specialty Meats",
      "slug": "cajun-specialty-meats",
      "category": "Web Development - Small Business",
      "status": "Active",
      "featured": false,
      "order": 6,
      "projectDescription": "A professional small-business website for local business Down the Bayou Cajun Specialty Meats. Demonstrates ability to deliver client-facing web solutions for local businesses.",
      "shortDescription": "Small business website for a Cajun specialty meats company.",
      "narrative": "Small businesses need a digital footprint as robust as their products. This project was a focused effort to deliver a clean, professional web presence for a local Cajun specialty meat provider.",
      "conceptualArchitecture": "The site follows a 'Mobile-First' responsive architecture, prioritizing local accessibility. It uses high-fidelity visual assets and optimized load-patterns to ensure a premium experience on both low-bandwidth mobile networks and desktop displays.",
      "myRole": "Web Developer - Full design and development",
      "responsibilities": [
        "Client requirements gathering and brand alignment.",
        "Responsive UI/UX design showcasing local products.",
        "Mobile-first Layout: Optimized for local customers on-the-go.",
        "Deployment and hosting setup on Bluehost for 100% reliability."
      ],
      "techStack": [
        "HTML5",
        "CSS3",
        "JavaScript",
        "Vercel"
      ],
      "techCategories": {
        "frontend": [
          "HTML5",
          "CSS3",
          "JavaScript"
        ],
        "platform": [
          "Vercel"
        ]
      },
      "challengesFaced": [
        {
          "challenge": "Brand Authenticity",
          "description": "The client needed the site to feel 'local' without looking 'amateur.'",
          "solution": "Used high-quality local photography and a refined, high-contrast color palette.",
          "result": "A professional site that maintains the local business feel."
        }
      ],
      "keyLearnings": [
        "Gained experience in client-facing web development",
        "Learned to translate business requirements into functional websites",
        "Developed skills in responsive design for small business sites"
      ],
      "impactMetrics": {
        "reach": "Increased online brand visibility for local business",
        "uptime": "100% on Bluehost platform"
      },
      "developmentTimeline": {
        "duration": "3 months"
      },
      "roadmap": [
        "Development of a full e-commerce migration to WooCommerce"
      ],
      "targetAudience": "Local customers and authentic Cajun meat enthusiasts",
      "projectURL": "https://downthebayoumeats.com",
      "images": []
    },
    {
      "id": "web-app-idea-management",
      "projectName": "Web App Idea Management",
      "slug": "web-app-idea-management",
      "category": "Web Development - Productivity Tool",
      "status": "Active",
      "featured": false,
      "order": 7,
      "projectDescription": "A specialized database application for organizing and ranking development ideas. It serves as a personal innovation pipeline for multi-disciplinary solutions.",
      "shortDescription": "Personal innovation pipeline and database for web app ideas.",
      "narrative": "Great ideas are easily lost. This tool was built to capture and organize potential projects, ranking them by feasibility and impact to create a personal innovation pipeline.",
      "conceptualArchitecture": "Architected as a real-time CRUD application using Firebase, the tool implements a 'Feasibility Weighted Ranking' system. This allows for dynamic prioritization of long-term innovation vs. immediate development opportunities based on weighted time-impact metrics.",
      "myRole": "Sole Developer - Full-stack implementation",
      "responsibilities": [
        "Database schema design for hierarchical idea storage.",
        "Feasibility Ranking: Algorithm that weights time vs. impact.",
        "Search & Category Filtering: Instant retrieval of domain-specific ideas.",
        "Modular Data Logic: Ability to export idea sets for collaboration."
      ],
      "techStack": [
        "React 18 + Vite for fast development",
        "Firebase Backend - Firestore database with real-time capabilities",
        "Tailwind CSS - Utility-first CSS framework for styling",
        "ESLint - Code quality and consistency",
        "Firebase Hosting - Production deployment"
      ],
      "techCategories": {
        "frontend": [
          "React 18",
          "Vite",
          "Tailwind CSS"
        ],
        "backend": [
          "Firebase (Firestore, Authentication, Hosting)"
        ],
        "apis": [
          "GitHub API for trending repositories"
        ],
        "development": [
          "ESLint",
          "PostCSS"
        ]
      },
      "challengesFaced": [
        {
          "challenge": "Dynamic Categorization",
          "description": "Users needed to easily move ideas between 'Backlog' and 'Development' without complex UI steps.",
          "solution": "Implemented a lightweight state-switching logic for instant status updates.",
          "result": "Fast, frictionless management of 50+ project ideas."
        }
      ],
      "keyLearnings": [
        "Learned database design patterns for flexible content storage",
        "Developed CRUD application architecture skills",
        "Gained experience in personal productivity tool development"
      ],
      "impactMetrics": {
        "organization": "Organized 50+ unique development concepts",
        "usability": "Zero-friction idea capture"
      },
      "developmentTimeline": {
        "duration": "1 week"
      },
      "roadmap": [
        "Adding AI-powered 'Project Feasibility' analysis"
      ],
      "targetAudience": "Developers and innovative problem solvers",
      "projectURL": "https://idea-board-app.web.app",
      "repoURL": "https://github.com/rguid31/web-app-idea-management",
      "images": []
    },
    {
      "id": "neuromorphic-portfolio",
      "projectName": "Neuromorphic Portfolio",
      "slug": "neuromorphic-portfolio",
      "category": "Web Development - Next-Generation UI/UX",
      "status": "Archived",
      "featured": false,
      "order": 8,
      "projectDescription": "Built with Next.js 15, this project explored high-fidelity UI/UX through glassmorphism and neumorphism. It served as the experimental predecessor to the current Digital Twin platform.",
      "shortDescription": "Next.js 15 portfolio with neuromorphic design system.",
      "narrative": "Before the Digital Twin architecture, I focused on high-fidelity visual design. The Neuromorphic Portfolio was an experiment in glassmorphism and advanced CSS effects, serving as the experimental foundation for my current platform.",
      "conceptualArchitecture": "An experimental UI/UX architecture exploring the boundaries of 'Soft UI' and Glassmorphism. The system utilizes advanced CSS3 blurring and translucency filters, integrated with Framer Motion for organic, physics-based interface transitions.",
      "myRole": "Sole Developer & Designer - Complete creative and technical control",
      "responsibilities": [
        "Conceptualized neuromorphic design language.",
        "Architected Next.js 15 application using early App Router features.",
        "Glassmorphism Implementation: Mathematical blur and transparency logic.",
        "Interactive Animations: Leveraged Framer Motion for organic UI transitions.",
        "Deployment to Vercel with focus on visual load-times."
      ],
      "techStack": [
        "Next.js 15",
        "TypeScript 5+",
        "Tailwind CSS 3.4",
        "Framer Motion",
        "React 18",
        "Vercel"
      ],
      "techCategories": {
        "framework": [
          "Next.js 15"
        ],
        "styling": [
          "Glassmorphism (Custom CSS)",
          "Tailwind CSS 3.4"
        ],
        "animation": [
          "Framer Motion"
        ],
        "platform": [
          "Vercel"
        ]
      },
      "challengesFaced": [
        {
          "challenge": "Accessibility with Translucency",
          "description": "Maintaining readability while using heavy glassmorphism effects was difficult for high-contrast standards.",
          "solution": "Implemented dynamic text-shading that adjusted based on background saturation.",
          "result": "Unique visual identity with Lighthouse accessibility scores > 90."
        }
      ],
      "keyLearnings": [
        "Mastered Next.js 15 and React Server Components patterns",
        "Designed and implemented high-fidelity UI animations with Framer Motion",
        "Optimized complex visual effects for 60fps performance",
        "Learned atomic design principles for custom UI libraries"
      ],
      "impactMetrics": {
        "accessibility": "> 90 Lighthouse score",
        "performance": "95+ Lighthouse score",
        "visuals": "60fps organic animations"
      },
      "developmentTimeline": {
        "duration": "1 month"
      },
      "roadmap": [
        "Project reached maturity; archived in favor of the 'Digital Twin' architecture"
      ],
      "targetAudience": "UI/UX designers and creative developers",
      "projectURL": "https://neuromorphic-portfolio.vercel.app",
      "repoURL": "https://github.com/rguid31/neuromorphic-portfolio",
      "images": [
        "/assets/neuromorphic-display.png"
      ]
    }
  ],
  "education": [
    {
      "id": "lsu-mathematics-2025",
      "institution": "Louisiana State University",
      "degree": "Bachelor of Science (B.S.)",
      "field": "Mathematics with a Secondary Discipline in Chemical Engineering",
      "location": {
        "city": "Baton Rouge",
        "state": "Louisiana"
      },
      "startDate": "2025-08",
      "graduationDate": "2027-12",
      "dateLabel": "Expected Graduation",
      "gpa": null,
      "description": "Transferred from Chemical Engineering to Mathematics to focus on advanced data analysis and computational modeling, leveraging a strong engineering foundation.",
      "categorizedCoursework": {
        "Mathematics Foundations & Core Curriculum": [
          "MATH 1021 – College Algebra (credit by exam)",
          "MATH 1550 – Analytical Geometry & Calculus I",
          "MATH 1552 – Analytical Geometry & Calculus II",
          "MATH 2090 – Elementary Differential Equations & Linear Algebra",
          "MATH 2035 – Mathematics of Data Science",
          "MATH 2057 – Multidimensional Calculus"
        ]
      },
      "achievements": [
        "88/120 credit hours completed"
      ]
    },
    {
      "id": "lsu-che-incomplete",
      "institution": "Louisiana State University",
      "degree": "Bachelor's degree (incomplete)",
      "field": "Chemical Engineering",
      "location": {
        "city": "Baton Rouge",
        "state": "Louisiana"
      },
      "startDate": "2014-08",
      "graduationDate": "2023-12",
      "dateLabel": "Dates Attended",
      "gpa": null,
      "description": "Completed 131/139 credit hours in Chemical Engineering before pivoting to Mathematics to specialize in data science, analytics, and machine learning.",
      "categorizedCoursework": {
        "Chemical Engineering – Core & Supporting Coursework": [
          "CHE 1100 – Introduction to Chemical Engineering",
          "CHE 2162 – Computer Modeling",
          "CHE 2171 – Chemical Engineering Fundamentals: Material & Energy Balances",
          "CHE 2176 – Numerical Methods & Programming for Chemical Engineers",
          "CHE 3101 – Momentum Transfer",
          "CHE 3102 – Heat and Mass Transfer",
          "CHE 3104 – Engineering Measurement Laboratory",
          "CHE 3171 – Introduction to Design & Process Safety",
          "CHE 3172 – Chemical Engineering Thermodynamics",
          "CHE 3173 – Heterogeneous Equilibrium",
          "CHE 3190 – Chemical Reaction Engineering",
          "CHE 4198 – Process Dynamics",
          "CHE 4151 – Unit Operations Design",
          "CHE 4162 – Unit Operations Laboratory",
          "CHE 4210 – Industrial Catalysis",
          "CHE 4410 – Special Topics in Chemical Engineering Design",
          "CHE 4488 – Process Separations"
        ],
        "Chemistry & Physical Sciences Supporting Chemical Engineering": [
          "CHEM 1201 – General Chemistry I",
          "CHEM 1202 – General Chemistry II",
          "CHEM 1212 – General Chemistry Laboratory",
          "CHEM 2261 – Organic Chemistry I",
          "CHEM 2262 – Organic Chemistry II",
          "CHEM 2364 – Organic Chemistry Laboratory",
          "CHEM 3491 – Physical Chemistry I",
          "ENVS 4101 – Environmental Chemistry",
          "CHE 4260 – Biochemical Engineering"
        ],
        "Engineering, Math, and Physics Foundations Used in ChemE": [
          "ME 2733 – Materials of Engineering",
          "PHYS 2110 – Particle Mechanics",
          "PHYS 2113 – Electromagnetism",
          "MATH 1550 – Analytical Geometry & Calculus I",
          "MATH 1552 – Analytical Geometry & Calculus II",
          "MATH 2090 – Elementary Differential Equations & Linear Algebra"
        ]
      },
      "achievements": [
        "131/139 credit hours completed"
      ]
    },
    {
      "id": "destrehan-high-school",
      "institution": "Destrehan High School",
      "degree": "High School Diploma",
      "field": "Honors Program",
      "location": {
        "city": "Destrehan",
        "state": "Louisiana"
      },
      "graduationDate": "2014-05",
      "dateLabel": "Graduated",
      "description": "Focused on STEM subjects including electronics, robotics, drafting, engineering, and physics. Graduated from the Honors Program.",
      "achievements": [
        "Honors Program Graduate",
        "Member of the DHS Soccer Team",
        "Specialized coursework in STEM focused on engineering, electronics, robotics, and drafting"
      ]
    }
  ],
  "experience": [
    {
      "id": "down-the-bayou-meats-role",
      "title": "Lead Systems Developer & Brand Architect",
      "company": "Down the Bayou Meats",
      "employmentType": "Freelance",
      "location": "Baton Rouge, LA",
      "startDate": "2025-12",
      "endDate": null,
      "current": true,
      "description": "Architected and deployed a comprehensive digital presence for an award-winning Cajun specialty meat brand, bridging traditional heritage with modern retail technology.",
      "responsibilities": [
        "Managed end-to-end infrastructure deployment including domain registration, DNS configuration, and SSL implementation for secure data transmission.",
        "Developed a semantic SEO strategy utilizing machine-readable metadata and descriptive alt-text to enhance AI recognizability and search discoverability.",
        "Engineered professional communication channels by configuring SMTP protocols and domain-based email through Google Workspace.",
        "Designed and implemented a responsive 3-column 'Brand Showcase' utilizing Flexbox math and relative viewport units (VH/VW) for device-agnostic performance.",
        "Constructed lead-generation workflows and mailing list segments via integrated Contact Form 7 to drive regional customer engagement.",
        "Established a WCAG-compliant high-contrast color palette (Barn Red, Gold, Cream) to ensure web accessibility and brand consistency."
      ],
      "skills": [
        "WordPress",
        "Elementor Pro",
        "Google Workspace",
        "DNS/SSL/SMTP",
        "Yoast SEO",
        "Schema.org"
      ],
      "achievements": [
        "Successfully migrated the brand from concept to a live, secure infrastructure with 99.9% uptime while maintaining mobile-responsive UX standards across diverse hardware."
      ]
    },
    {
      "id": "outlier-ai-math-specialist",
      "title": "AI Math Specialist",
      "company": "OutlierAI",
      "employmentType": "Freelance",
      "location": "Baton Rouge, Louisiana",
      "startDate": "2024-06",
      "endDate": null,
      "current": true,
      "description": "Training and evaluating generative AI models to enhance mathematical reasoning and response accuracy.",
      "responsibilities": [
        "Generate high-quality training data for STEM subjects to advance model capabilities",
        "Train AI models by rating, reviewing, and rewriting responses (RLHF) to enhance accuracy",
        "Evaluate model performance on complex mathematical problems",
        "Improve the relationship between human intent and AI data processing"
      ],
      "skills": [
        "Reinforcement Learning from Human Feedback (RLHF)",
        "Mathematical Modeling",
        "AI Evaluation",
        "Prompt Engineering",
        "Data Labeling"
      ],
      "achievements": [
        "Improved accuracy of math-related model outputs",
        "Consistently maintained high quality ratings for training data generation"
      ]
    },
    {
      "id": "tracerco-field-technician",
      "title": "Field Technician",
      "company": "Tracerco",
      "employmentType": "Contract",
      "location": "Baton Rouge, Louisiana",
      "startDate": "2024-04",
      "endDate": "2024-05",
      "current": false,
      "description": "Technical innovation role focusing on scanning, tracing, and nucleonic instrumentation.",
      "responsibilities": [
        "Oversaw technical innovation as a subject matter expert in core technologies (scanning, tracing, nucleonic instrumentation)",
        "Maintained strategic client partnerships to deliver tailored solutions",
        "Enhanced operational efficiency and safety across diverse industries through data-driven diagnostics"
      ],
      "skills": [
        "Nucleonic Instrumentation",
        "Field Data Collection",
        "Process Diagnostics",
        "Client Relationship Management"
      ],
      "achievements": []
    },
    {
      "id": "acbl-safety-coordinator",
      "title": "Safety and Training Coordinator",
      "company": "American Commercial Barge Line (ACBL)",
      "employmentType": "Full-time",
      "location": "Harahan, Louisiana",
      "startDate": "2023-10",
      "endDate": "2024-03",
      "current": false,
      "description": "Cultivated a proactive safety culture through data analysis and training initiatives.",
      "responsibilities": [
        "Cultivated a proactive safety culture through promotion of safe work practices",
        "Streamlined reporting procedures resulting in improved compliance ratings",
        "Empowered employees through engaging safety training sessions",
        "Proactively identified and mitigated potential safety hazards through expert analysis",
        "Maintained safety programs at the forefront of industry standards"
      ],
      "skills": [
        "Safety Data Analysis",
        "Training Facilitation",
        "Risk Mitigation",
        "Regulatory Compliance",
        "Process Improvement"
      ],
      "achievements": [
        "Improved compliance ratings",
        "Reduced reporting turnaround times"
      ]
    },
    {
      "id": "emerson-application-engineer",
      "title": "Application Engineer",
      "company": "Emerson Automation Solutions",
      "employmentType": "Internship",
      "location": "Baton Rouge, Louisiana",
      "startDate": "2022-06",
      "endDate": "2022-08",
      "current": false,
      "description": "Developed automation solutions and software configurations for industrial control systems.",
      "responsibilities": [
        "Established AgileOps suite of software applications on DeltaV, Honeywell, and Siemens platforms",
        "Directed proposition to deploy admin distribution management (WSUS) to over 1200 virtual machines",
        "Coded Excel macros in VBA to automate UI customization and maximize user efficiency",
        "Pre-populated Site Information Documents using plant data from customer .FHX files"
      ],
      "skills": [
        "VBA Scripting",
        "Windows Server Administration (WSUS)",
        "SQL",
        "AgileOps",
        "Data Parsing"
      ],
      "achievements": [
        "Automated security and maintenance updates for company network",
        "Simplified user experience through custom Excel tooling"
      ]
    },
    {
      "id": "totalenergies-project-intern",
      "title": "Project Engineering Intern",
      "company": "TotalEnergies",
      "employmentType": "Internship",
      "location": "Port Arthur, Texas",
      "startDate": "2021-06",
      "endDate": "2021-08",
      "current": false,
      "description": "Led pre-FEED planning and process simulation for refinery optimization projects.",
      "responsibilities": [
        "Led pre-FEED planning for Condensate Splitter Unit (CSU) optimization project",
        "Created working model of refinery CWS piping network using SimSci Pipephase software",
        "Constructed test data sheets for evaluating VFD pump performance",
        "Studied feasibility of CSU modifications for improved corrosion control"
      ],
      "skills": [
        "SimSci Pipephase",
        "Project Management",
        "Process Simulation",
        "Data Analysis",
        "Cost Estimation"
      ],
      "achievements": [
        "Delivered comprehensive execution plan for FEED phase",
        "Successfully modeled complex piping network"
      ]
    },
    {
      "id": "dwl-tech-sales-intern",
      "title": "Industrial Equipment Sales Intern",
      "company": "DWL Technology",
      "employmentType": "Internship",
      "location": "Walker, Louisiana",
      "startDate": "2019-05",
      "endDate": "2019-09",
      "current": false,
      "description": "Managed e-commerce operations, inventory, and sales analytics.",
      "responsibilities": [
        "Managed, organized, and sold surplus industrial engineering parts globally",
        "Created e-commerce sales presence with over 200 transactions",
        "Managed e-commerce sales metrics and KPIs to improve listing SEO",
        "Attained eBay Top-Rated Seller status"
      ],
      "skills": [
        "E-commerce Management",
        "SEO",
        "Sales Analytics",
        "Inventory Management",
        "Customer Service"
      ],
      "achievements": [
        "100% positive customer sales feedback",
        "Defect rating of less than 0.5%"
      ]
    },
    {
      "id": "nalco-tech-sales",
      "title": "Technical Sales Engineer",
      "company": "NALCO Champion",
      "employmentType": "Internship",
      "location": "Lafayette, Louisiana",
      "startDate": "2018-05",
      "endDate": "2018-08",
      "current": false,
      "description": "Provided specialty chemical recommendations and corrosion monitoring services.",
      "responsibilities": [
        "Conducted daily upstream oilfield surveys and provided chemical additive recommendations",
        "Revamped pipeline corrosion monitoring services using computer modeling",
        "correlated new failures with past data to forecast future flowline failures"
      ],
      "skills": [
        "Corrosion Monitoring",
        "Chemical Modeling",
        "Data Correlation",
        "Technical Sales"
      ],
      "achievements": []
    },
    {
      "id": "cornerstone-process-intern",
      "title": "Process Engineering Intern",
      "company": "Cornerstone Chemical Company",
      "employmentType": "Internship",
      "location": "Westwego, Louisiana",
      "startDate": "2017-12",
      "endDate": "2018-01",
      "current": false,
      "description": "Analyzed plant data and equipment performance.",
      "responsibilities": [
        "Utilized Pi ProcessBook and Pi Datalink to analyze plant data on production costs",
        "Verified P&IDs with lead process engineers",
        "Examined industrial turbines and compressors for failure mechanisms"
      ],
      "skills": [
        "Pi ProcessBook",
        "Data Analysis",
        "Process Engineering",
        "P&ID Verification"
      ],
      "achievements": []
    },
    {
      "id": "new-orleans-daiquiris-bartender",
      "title": "Bartender",
      "company": "New Orleans Original Daiquiris",
      "employmentType": "Part-time",
      "location": "Baton Rouge, Louisiana",
      "startDate": "2017-07",
      "endDate": "2017-09",
      "current": false,
      "description": "Provided customer service and maintained operations in a fast-paced environment.",
      "responsibilities": [
        "Developed customer business relations through effective social interaction",
        "Ensured customer satisfaction in a fast-paced environment",
        "Exhibited strong time management and work ethic balancing school and work"
      ],
      "skills": [
        "Customer Service",
        "Time Management",
        "Communication",
        "Operations"
      ],
      "achievements": []
    },
    {
      "id": "gp-chemical-sales-intern-nj",
      "title": "Chemical Sales Intern",
      "company": "Georgia-Pacific LLC",
      "employmentType": "Internship",
      "location": "Hasbrouck Heights, New Jersey",
      "startDate": "2016-12",
      "endDate": "2017-01",
      "current": false,
      "description": "Participated in chemical trials and customer facility service.",
      "responsibilities": [
        "Participated in chemical trials to gain service of a customer facility",
        "Completed wet-end testing on pulp samples (system charge, pH, conductivity, turbidity)"
      ],
      "skills": [
        "Chemical Testing",
        "Client Service",
        "Technical Analysis",
        "Lab Procedures"
      ],
      "achievements": []
    },
    {
      "id": "gp-chemical-sales-intern-ny",
      "title": "Chemical Sales Intern",
      "company": "Georgia-Pacific LLC",
      "employmentType": "Internship",
      "location": "New York, Pennsylvania, New Jersey",
      "startDate": "2016-05",
      "endDate": "2016-08",
      "current": false,
      "description": "Optimized chemical processes and conducted technical studies at paper mills.",
      "responsibilities": [
        "Conducted wet-end tests and optimized chemical additive injection rates",
        "Performed pulp receptivity studies on recycled furnishes",
        "Created PFDs of paper making process for optimal injection location"
      ],
      "skills": [
        "Process Optimization",
        "Technical Analysis",
        "PFD Creation",
        "Cost Reduction"
      ],
      "achievements": [
        "Minimized production costs through optimization",
        "Met product benchmarks"
      ]
    },
    {
      "id": "home-servicing-mortgage-lender",
      "title": "Mortgage Lender",
      "company": "Home Servicing, LLC",
      "employmentType": "Seasonal",
      "location": "Baton Rouge, Louisiana",
      "startDate": "2015-05",
      "endDate": "2015-08",
      "current": false,
      "description": "Managed mortgage communications and documentation. Also worked Winter Break 2014.",
      "responsibilities": [
        "Communicated with homeowners and agents regarding taxes, insurance, and mortgages",
        "Organized and filed paperwork into computer database and physical library",
        "Acquired customer information using Service Director and Citrix programs"
      ],
      "skills": [
        "Data Entry",
        "Customer Communication",
        "Document Management",
        "Citrix"
      ],
      "achievements": [
        " improved accessibility of customer information"
      ]
    },
    {
      "id": "st-charles-computer-tech",
      "title": "Computer Technician",
      "company": "St. Charles Parish Public Schools",
      "employmentType": "Summer",
      "location": "Destrehan, Louisiana",
      "startDate": "2014-05",
      "endDate": "2014-08",
      "current": false,
      "description": "Deployed and optimized school technology infrastructure. Also worked Summer 2013.",
      "responsibilities": [
        "Efficiently installed and configured computers and software across classrooms",
        "Provided timely troubleshooting of hardware, software, and network issues",
        "Developed and implemented an efficient photo identification system"
      ],
      "skills": [
        "IT Support",
        "Hardware Deployment",
        "Network Configuration",
        "System Administration"
      ],
      "achievements": [
        "Streamlined school identification process",
        "Maximized utilization of technology resources"
      ]
    }
  ],
  "skills": {
    "programming": {
      "category": "Programming Languages",
      "items": [
        {
          "name": "JavaScript/TypeScript",
          "level": "Advanced",
          "yearsOfExperience": 3,
          "context": "Production experience with Next.js, React, Node.js"
        },
        {
          "name": "Python",
          "level": "Advanced",
          "yearsOfExperience": 3,
          "context": "CLI tools, automation, data processing, AI/ML integration"
        },
        {
          "name": "HTML/CSS",
          "level": "Advanced",
          "yearsOfExperience": 3,
          "context": "Modern semantic HTML5, CSS3, responsive design"
        },
        {
          "name": "SQL",
          "level": "Intermediate",
          "yearsOfExperience": 2,
          "context": "PostgreSQL, database design, queries"
        },
        {
          "name": "MATLAB",
          "level": "Intermediate",
          "yearsOfExperience": 4,
          "context": "Engineering analysis and computation"
        }
      ]
    },
    "frameworks": {
      "category": "Frameworks & Libraries",
      "items": [
        {
          "name": "React 18",
          "level": "Advanced"
        },
        {
          "name": "Next.js 14/15",
          "level": "Advanced"
        },
        {
          "name": "Tailwind CSS",
          "level": "Advanced"
        },
        {
          "name": "Framer Motion",
          "level": "Intermediate"
        },
        {
          "name": "Node.js",
          "level": "Advanced"
        },
        {
          "name": "Express.js",
          "level": "Advanced"
        }
      ]
    },
    "aiml": {
      "category": "AI/ML Technologies",
      "items": [
        {
          "name": "OpenAI API (CLIP, GPT-4)",
          "level": "Advanced"
        },
        {
          "name": "Google Gemini API",
          "level": "Advanced"
        },
        {
          "name": "Prompt Engineering",
          "level": "Advanced"
        },
        {
          "name": "Embeddings & Vector Databases",
          "level": "Intermediate"
        },
        {
          "name": "LangChain",
          "level": "Beginner"
        }
      ]
    },
    "databases": {
      "category": "Databases & Data Storage",
      "items": [
        {
          "name": "PostgreSQL (Supabase)",
          "level": "Advanced"
        },
        {
          "name": "SQLite",
          "level": "Intermediate"
        },
        {
          "name": "MongoDB",
          "level": "Intermediate"
        },
        {
          "name": "Firebase",
          "level": "Intermediate"
        }
      ]
    },
    "devops": {
      "category": "DevOps & Tools",
      "items": [
        {
          "name": "Git",
          "level": "Advanced"
        },
        {
          "name": "GitHub",
          "level": "Advanced"
        },
        {
          "name": "Vercel",
          "level": "Advanced"
        },
        {
          "name": "AWS",
          "level": "Beginner"
        },
        {
          "name": "CI/CD",
          "level": "Intermediate"
        }
      ]
    },
    "technicalWriting": {
      "category": "Technical Writing & Documentation",
      "items": [
        {
          "name": "API Documentation",
          "level": "Advanced"
        },
        {
          "name": "User Guides",
          "level": "Advanced"
        },
        {
          "name": "Developer Tutorials",
          "level": "Advanced"
        },
        {
          "name": "Markdown/MDX",
          "level": "Advanced"
        },
        {
          "name": "Docusaurus/GitBook",
          "level": "Intermediate"
        }
      ]
    }
  },
  "certifications": [
    {
      "id": "google-data-analytics",
      "name": "Google Data Analytics Professional Certificate",
      "issuer": "Google (via Coursera)",
      "status": "In Progress",
      "startDate": "2023-09",
      "completionDate": null,
      "credentialID": null,
      "credentialURL": null,
      "skills": [
        "Data cleaning",
        "SQL",
        "Data visualization",
        "R programming",
        "Statistical analysis"
      ]
    },
    {
      "id": "google-ai-essentials",
      "name": "Google AI Essentials",
      "issuer": "Google",
      "status": "Needs Verification",
      "startDate": null,
      "completionDate": null,
      "credentialID": null,
      "credentialURL": null,
      "skills": [
        "AI fundamentals",
        "Responsible AI"
      ]
    },
    {
      "id": "osha-basic-orientation",
      "name": "OSHA Basic Orientation Plus",
      "issuer": "OSHA",
      "status": "Active",
      "issueDate": null,
      "expirationDate": null,
      "credentialType": "Physical Card",
      "skills": [
        "Workplace safety",
        "Hazard recognition",
        "OSHA compliance"
      ]
    },
    {
      "id": "twic",
      "name": "Transportation Worker Identification Credential (TWIC)",
      "issuer": "TSA",
      "status": "Active (Needs Verification)",
      "issueDate": null,
      "expirationDate": null,
      "credentialType": "Physical Card (Biometric)",
      "skills": [
        "Maritime security clearance"
      ]
    }
  ],
  "volunteer": [
    {
      "id": "google-ux-researcher",
      "role": "User Experience Researcher",
      "organization": "Google",
      "startDate": "2022-11",
      "endDate": null,
      "current": true,
      "description": "Volunteer contributor to Google's UX research initiatives, providing user feedback and insights to improve product experiences.",
      "responsibilities": [
        "Participate in user testing sessions for Google products",
        "Complete feedback surveys and usability studies",
        "Provide insights on product features and user experience",
        "Test new features and provide detailed feedback"
      ]
    },
    {
      "id": "google-local-guide",
      "role": "Local Guide (Level 5)",
      "organization": "Google Maps",
      "startDate": null,
      "endDate": null,
      "current": true,
      "level": 5,
      "description": "Active contributor to Google Maps, providing high-quality reviews, photos, and location information.",
      "contributions": {
        "reviews": "Multiple",
        "photos": "Multiple",
        "edits": "Multiple"
      }
    }
  ],
  "hobbies": [
    {
      "id": "vinyl-collecting",
      "name": "Vinyl Collecting",
      "description": "Avid collector of vinyl records with a focus on rock and alternative genres. Check out my collection on Discogs.",
      "category": "Collecting",
      "url": "https://www.discogs.com/user/Rockit_Media",
      "linkText": "My Discogs profile",
      "image": "/images/hobbies/vinyl.png",
      "featured": true
    },
    {
      "id": "graphic-design",
      "name": "Graphic Design",
      "description": "Creating visual assets for web and print. Passionate about typography and layout design.",
      "category": "Creative",
      "url": "/designs",
      "linkText": "View my designs",
      "image": "/images/hobbies/design.png"
    },
    {
      "id": "web-app-dev",
      "name": "Web/App Development",
      "description": "Building useful tools and applications. Constantly learning new frameworks and technologies.",
      "category": "Technology",
      "url": "https://github.com/rguid31",
      "linkText": "See my code",
      "image": "/images/hobbies/coding.png",
      "featured": true
    },
    {
      "id": "ebay-store",
      "name": "eBay Reselling",
      "description": "Running 'Ryans Rocket Shop', an online store for vintage items and collectibles.",
      "category": "Business",
      "url": "https://www.ebay.com/usr/ryans_rocket_shop",
      "linkText": "Check out my eBay store",
      "image": "/images/hobbies/ebay.png"
    },
    {
      "id": "landoni-music",
      "name": "LANDONi Music",
      "description": "Logo and merchandise designer, videography producer, social media manager, and manager for LANDONi Music, New Orleans electronic music producer and DJ.",
      "category": "Music",
      "url": "https://www.youtube.com/@LANDONiMusic",
      "linkText": "Listen to LANDONi",
      "image": "/images/hobbies/music.png"
    },
    {
      "id": "blockchain",
      "name": "Blockchain & Decentralization",
      "description": "Fascinated by the technical and social implications of blockchain technology, with a strong focus on decentralization, distributed ledgers, and the future of web3.",
      "category": "Technology",
      "url": "https://bitcoin.org/bitcoin.pdf",
      "linkText": "Read the whitepaper that started it all",
      "image": "/images/hobbies/blockchain.png"
    }
  ],
  "insightsProfile": {
    "profileType": "Reforming Observer",
    "energies": {
      "coolBlue": 64,
      "fieryRed": 60,
      "sunshineYellow": 33,
      "earthGreen": 43
    },
    "strengths": [
      "Analytical Rigor - Strong ability to analyze complex problems systematically",
      "Results-Oriented - Driven to achieve tangible outcomes and measurable results",
      "Independent Thinking - Comfortable working autonomously with minimal supervision",
      "High Standards - Maintains quality and accuracy in all work",
      "Efficient Execution - Balances thorough analysis with timely decision-making"
    ],
    "communicationStyle": {
      "prefers": "Data-driven discussions, logical arguments, clear objectives",
      "values": "Precision, efficiency, competence, independence",
      "approach": "Direct, factual, focused on outcomes"
    },
    "workPreferences": {
      "idealEnvironment": "Structured yet autonomous, with clear goals and metrics",
      "motivation": "Solving complex problems, achieving measurable results",
      "decisionMaking": "Evidence-based analysis combined with decisive action"
    }
  }
}